{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -c \"import onnxruntime\" || pip install -q onnxruntime\n",
    "import onnxruntime\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "\n",
    "from main_nerv_inv import make_cameras_dea, DXRLightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392\n",
      "['/home/quantm/data/ChestXRLungSegmentation/MELA2022/raw/train/images/mela_0001.nii.gz']\n",
      "15000\n",
      "['/home/quantm/data/ChestXRLungSegmentation/VinDr/v1/processed/train/images/000434271f63a053c4128a0ba6352c7f.png']\n",
      "771\n",
      "['/home/quantm/data/ChestXRLungSegmentation/TCIA/CT-Covid-19-2020/images/volume-covid19-A-0000.nii.gz']\n",
      "3000\n",
      "['/home/quantm/data/ChestXRLungSegmentation/VinDr/v1/processed/test/images/002a34c58c5b758217ed1f584ccbcfe9.png']\n",
      "771\n",
      "['/home/quantm/data/ChestXRLungSegmentation/TCIA/CT-Covid-19-2020/images/volume-covid19-A-0000.nii.gz']\n",
      "3000\n",
      "['/home/quantm/data/ChestXRLungSegmentation/VinDr/v1/processed/test/images/002a34c58c5b758217ed1f584ccbcfe9.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datamodule import UnpairedDataModule\n",
    "\n",
    "from typing import NamedTuple, Optional, Union\n",
    "\n",
    "class Hparams(NamedTuple):\n",
    "    lr: float=1e-4\n",
    "    ckpt: str=\"temp\"\n",
    "    datadir: str=None\n",
    "    strict: str=None\n",
    "    alpha: float=1.0\n",
    "    gamma: float=1.0\n",
    "    delta: float=1.0\n",
    "    theta: float=1.0\n",
    "    omega: float=1.0\n",
    "    lamda: float=1.0\n",
    "    timesteps: int=1000\n",
    "    logsdir: str=None\n",
    "    sh: int=0\n",
    "    pe: int=0\n",
    "\n",
    "    n_pts_per_ray: int=400\n",
    "    weight_decay: float=1e-2\n",
    "    devices: torch.device=torch.device('cpu')\n",
    "    backbone: str=\"efficientnet-b7\"\n",
    "    train_samples: int=100\n",
    "    val_samples: int=100\n",
    "    test_samples: int=100\n",
    "    img_shape: int=256\n",
    "    vol_shape: int=256\n",
    "    fov_depth: int=256\n",
    "    batch_size: int=1\n",
    "\n",
    "hparams = Hparams(\n",
    "    ckpt=None,\n",
    "    datadir=\"/home/quantm/data\", \n",
    "    train_samples=1, \n",
    "    val_samples=1, \n",
    "    test_samples=1,\n",
    "    img_shape=256,\n",
    "    vol_shape=256,\n",
    "    batch_size=1 \n",
    ")\n",
    "\n",
    "# Create data module\n",
    "train_image3d_folders = [\n",
    "    os.path.join(hparams.datadir, \"ChestXRLungSegmentation/NSCLC/processed/train/images\"),\n",
    "    os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MOSMED/processed/train/images/CT-0\",),\n",
    "    os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MOSMED/processed/train/images/CT-1\",),\n",
    "    os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MOSMED/processed/train/images/CT-2\",),\n",
    "    os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MOSMED/processed/train/images/CT-3\",),\n",
    "    os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MOSMED/processed/train/images/CT-4\",),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/Imagenglab/processed/train/images'),\n",
    "    os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MELA2022/raw/train/images\"),\n",
    "    os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MELA2022/raw/val/images\"),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/AMOS2022/raw/train/images'),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/AMOS2022/raw/val/images'),\n",
    "]\n",
    "\n",
    "train_label3d_folders = []\n",
    "\n",
    "train_image2d_folders = [\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/JSRT/processed/images/'),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/ChinaSet/processed/images/'),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/Montgomery/processed/images/'),\n",
    "    os.path.join(hparams.datadir, \"ChestXRLungSegmentation/VinDr/v1/processed/train/images/\"),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/VinDr/v1/processed/test/images/'),\n",
    "]\n",
    "\n",
    "train_label2d_folders = []\n",
    "\n",
    "val_image3d_folders = [\n",
    "    # os.path.join(hparams.datadir, \"ChestXRLungSegmentation/NSCLC/processed/train/images\"),\n",
    "    # os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MOSMED/processed/train/images/CT-0\",),\n",
    "    # os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MOSMED/processed/train/images/CT-1\",),\n",
    "    # os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MOSMED/processed/train/images/CT-2\",),\n",
    "    # os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MOSMED/processed/train/images/CT-3\",),\n",
    "    # os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MOSMED/processed/train/images/CT-4\",),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/Imagenglab/processed/train/images'),\n",
    "    # os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MELA2022/raw/train/images\"),\n",
    "    # os.path.join(hparams.datadir, \"ChestXRLungSegmentation/MELA2022/raw/val/images\"),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/AMOS2022/raw/train/images'),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/AMOS2022/raw/val/images'),\n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/TCIA/CT-Covid-19-2020/images'),\n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/TCIA/CT-Covid-19-2021/images'),\n",
    "]\n",
    "\n",
    "val_image2d_folders = [\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/JSRT/processed/images/'),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/ChinaSet/processed/images/'),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/Montgomery/processed/images/'),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/VinDr/v1/processed/train/images/'),\n",
    "    os.path.join(hparams.datadir, \"ChestXRLungSegmentation/VinDr/v1/processed/test/images/\"),\n",
    "]\n",
    "\n",
    "test_image3d_folders = val_image3d_folders\n",
    "test_image2d_folders = val_image2d_folders\n",
    "\n",
    "\n",
    "dm = UnpairedDataModule(\n",
    "    train_image3d_folders=train_image3d_folders,\n",
    "    train_image2d_folders=train_image2d_folders,\n",
    "    val_image3d_folders=val_image3d_folders,\n",
    "    val_image2d_folders=val_image2d_folders,\n",
    "    test_image3d_folders=test_image3d_folders,\n",
    "    test_image2d_folders=test_image2d_folders,\n",
    "    train_samples=hparams.train_samples,\n",
    "    val_samples=hparams.val_samples,\n",
    "    test_samples=hparams.test_samples,\n",
    "    batch_size=hparams.batch_size,\n",
    "    img_shape=hparams.img_shape,\n",
    "    vol_shape=hparams.vol_shape\n",
    ")\n",
    "dm.setup()\n",
    "# for idx, batch in enumerate(dm.val_dataloader()):\n",
    "#     image3d = batch[\"image3d\"]\n",
    "#     print(image3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Module [DXRLightningModule] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/quantm/DXR/Serving.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.152.51.92/home/quantm/DXR/Serving.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m view_hidden \u001b[39m=\u001b[39m make_cameras_dea(dist_hidden, elev_hidden, azim_hidden, fov\u001b[39m=\u001b[39m\u001b[39m18\u001b[39m, znear\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, zfar\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B163.152.51.92/home/quantm/DXR/Serving.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m onnxpath \u001b[39m=\u001b[39m ckptpath\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.ckpt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.onnx\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B163.152.51.92/home/quantm/DXR/Serving.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39;49mto_onnx(onnxpath, image2d, export_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1377\u001b[0m, in \u001b[0;36mLightningModule.to_onnx\u001b[0;34m(self, file_path, input_sample, **kwargs)\u001b[0m\n\u001b[1;32m   1374\u001b[0m input_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_before_batch_transfer(input_sample)\n\u001b[1;32m   1375\u001b[0m input_sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_batch_transfer_handler(input_sample)\n\u001b[0;32m-> 1377\u001b[0m torch\u001b[39m.\u001b[39;49monnx\u001b[39m.\u001b[39;49mexport(\u001b[39mself\u001b[39;49m, input_sample, file_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain(mode)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/onnx/utils.py:506\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39m@_beartype\u001b[39m\u001b[39m.\u001b[39mbeartype\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(\n\u001b[1;32m    190\u001b[0m     model: Union[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptModule, torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     export_modules_as_functions: Union[\u001b[39mbool\u001b[39m, Collection[Type[torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule]]] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    207\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[39m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m     _export(\n\u001b[1;32m    507\u001b[0m         model,\n\u001b[1;32m    508\u001b[0m         args,\n\u001b[1;32m    509\u001b[0m         f,\n\u001b[1;32m    510\u001b[0m         export_params,\n\u001b[1;32m    511\u001b[0m         verbose,\n\u001b[1;32m    512\u001b[0m         training,\n\u001b[1;32m    513\u001b[0m         input_names,\n\u001b[1;32m    514\u001b[0m         output_names,\n\u001b[1;32m    515\u001b[0m         operator_export_type\u001b[39m=\u001b[39;49moperator_export_type,\n\u001b[1;32m    516\u001b[0m         opset_version\u001b[39m=\u001b[39;49mopset_version,\n\u001b[1;32m    517\u001b[0m         do_constant_folding\u001b[39m=\u001b[39;49mdo_constant_folding,\n\u001b[1;32m    518\u001b[0m         dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m    519\u001b[0m         keep_initializers_as_inputs\u001b[39m=\u001b[39;49mkeep_initializers_as_inputs,\n\u001b[1;32m    520\u001b[0m         custom_opsets\u001b[39m=\u001b[39;49mcustom_opsets,\n\u001b[1;32m    521\u001b[0m         export_modules_as_functions\u001b[39m=\u001b[39;49mexport_modules_as_functions,\n\u001b[1;32m    522\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/onnx/utils.py:1548\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1545\u001b[0m     dynamic_axes \u001b[39m=\u001b[39m {}\n\u001b[1;32m   1546\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1548\u001b[0m graph, params_dict, torch_out \u001b[39m=\u001b[39m _model_to_graph(\n\u001b[1;32m   1549\u001b[0m     model,\n\u001b[1;32m   1550\u001b[0m     args,\n\u001b[1;32m   1551\u001b[0m     verbose,\n\u001b[1;32m   1552\u001b[0m     input_names,\n\u001b[1;32m   1553\u001b[0m     output_names,\n\u001b[1;32m   1554\u001b[0m     operator_export_type,\n\u001b[1;32m   1555\u001b[0m     val_do_constant_folding,\n\u001b[1;32m   1556\u001b[0m     fixed_batch_size\u001b[39m=\u001b[39;49mfixed_batch_size,\n\u001b[1;32m   1557\u001b[0m     training\u001b[39m=\u001b[39;49mtraining,\n\u001b[1;32m   1558\u001b[0m     dynamic_axes\u001b[39m=\u001b[39;49mdynamic_axes,\n\u001b[1;32m   1559\u001b[0m )\n\u001b[1;32m   1561\u001b[0m \u001b[39m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m defer_weight_export \u001b[39m=\u001b[39m (\n\u001b[1;32m   1563\u001b[0m     export_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _exporter_states\u001b[39m.\u001b[39mExportTypes\u001b[39m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1564\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/onnx/utils.py:1113\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1110\u001b[0m     args \u001b[39m=\u001b[39m (args,)\n\u001b[1;32m   1112\u001b[0m model \u001b[39m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1113\u001b[0m graph, params, torch_out, module \u001b[39m=\u001b[39m _create_jit_graph(model, args)\n\u001b[1;32m   1114\u001b[0m params_dict \u001b[39m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1116\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/onnx/utils.py:989\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    984\u001b[0m     graph \u001b[39m=\u001b[39m _C\u001b[39m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m    985\u001b[0m         graph, flattened_args, param_count_list, \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    986\u001b[0m     )\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m graph, params, torch_out, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m graph, torch_out \u001b[39m=\u001b[39m _trace_and_get_graph_from_model(model, args)\n\u001b[1;32m    990\u001b[0m _C\u001b[39m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    991\u001b[0m state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/onnx/utils.py:893\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    891\u001b[0m prev_autocast_cache_enabled \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    892\u001b[0m torch\u001b[39m.\u001b[39mset_autocast_cache_enabled(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 893\u001b[0m trace_graph, torch_out, inputs_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49m_get_trace_graph(\n\u001b[1;32m    894\u001b[0m     model,\n\u001b[1;32m    895\u001b[0m     args,\n\u001b[1;32m    896\u001b[0m     strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    897\u001b[0m     _force_outplace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    898\u001b[0m     _return_inputs_states\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    899\u001b[0m )\n\u001b[1;32m    900\u001b[0m torch\u001b[39m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    902\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/jit/_trace.py:1268\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(args, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m   1267\u001b[0m     args \u001b[39m=\u001b[39m (args,)\n\u001b[0;32m-> 1268\u001b[0m outs \u001b[39m=\u001b[39m ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1269\u001b[0m \u001b[39mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/jit/_trace.py:127\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(out_vars)\n\u001b[0;32m--> 127\u001b[0m graph, out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_create_graph_by_tracing(\n\u001b[1;32m    128\u001b[0m     wrapper,\n\u001b[1;32m    129\u001b[0m     in_vars \u001b[39m+\u001b[39;49m module_state,\n\u001b[1;32m    130\u001b[0m     _create_interpreter_name_lookup_fn(),\n\u001b[1;32m    131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrict,\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_force_outplace,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs:\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m graph, outs[\u001b[39m0\u001b[39m], ret_inputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/jit/_trace.py:118\u001b[0m, in \u001b[0;36mONNXTracedModule.forward.<locals>.wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    117\u001b[0m     inputs_states\u001b[39m.\u001b[39mappend(_unflatten(in_args, in_desc))\n\u001b[0;32m--> 118\u001b[0m outs\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(\u001b[39m*\u001b[39;49mtrace_inputs))\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return_inputs_states:\n\u001b[1;32m    120\u001b[0m     inputs_states[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m (inputs_states[\u001b[39m0\u001b[39m], trace_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1488\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1489\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/lightning/pytorch/core/module.py:667\u001b[0m, in \u001b[0;36mLightningModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    658\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Same as :meth:`torch.nn.Module.forward`.\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \n\u001b[1;32m    660\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[39m        Your model's output\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 667\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:363\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    353\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \n\u001b[1;32m    355\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m] is missing the required \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mforward\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m function\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Module [DXRLightningModule] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "model = DXRLightningModule(hparams=hparams)\n",
    "ckptpath = '/home/quantm/epoch=99-step=12500.ckpt'\n",
    "model = model.load_from_checkpoint(\n",
    "    checkpoint_path=ckptpath\n",
    ")\n",
    "\n",
    "image2d = torch.randn((1, 1, 256, 256))\n",
    "dist_hidden = 6.0 * torch.ones(1, device=torch.device('cpu'))\n",
    "elev_hidden = torch.zeros(1, device=torch.device('cpu'))\n",
    "azim_hidden = torch.zeros(1, device=torch.device('cpu'))\n",
    "view_hidden = make_cameras_dea(dist_hidden, elev_hidden, azim_hidden, fov=18, znear=4, zfar=8)\n",
    "\n",
    "onnxpath = ckptpath.replace('.ckpt', '.onnx')\n",
    "model.to_onnx(onnxpath, image2d, export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
